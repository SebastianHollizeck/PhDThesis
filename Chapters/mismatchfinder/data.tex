
\section{Results}
\label{mmf-sec:results}
This section presents the results of applying MisMatchFinder to multiple distinct datasets with different configuration. \autoref{mmf-sec:simulated data} is the evaluation of the method on simulated data, which allowed accurate and definitive insight into the sensitivity of MisMatchFinder and a proof of concept. Then, \autoref{mmf-sec:realworld} summarises the results from multiple real world datasets, demonstrating that the method did not only work in cleanly simulated data, but also found clinically relevant insight in patient samples.

\subsection{Simulated Data - the validation promised land}
\label{mmf-sec:simulated data}
Just like in \autoref{ch:variantcalling}, the novelty of the approach led to the issue of absence of a gold standard dataset, with which to evaluate the performance of our new method. While there existed low coverage WGS datasets of cancer patients, none of them had validated signatures associated with them. So we simulated data, to allow both optimisation of parameters and granular detection of technical artefacts. 

\subsubsection{Sequencing errors - there is always a cleaner data}
\label{mmf-sec:cleanSim}
To judge the ability of our approach to filter out sequencing errors, we first simulated ``clean`` sequencing reads with neither germline or somatic variants with the ART simulation suite \cite{Huang2011}. As current estimates of Illumina sequencing error rates were in the range of 1 in 666 to 1 in 1149 \cite{Stoler2021} which was significantly higher than even the highest tumour mutational burdens of  cancers (melanoma: 1 in 5k; tobacco smoking lung cancer: 1 in 100k) it was very important to be able to eliminate as much of the background errors as possible.

\begin{figure}[ht]
\centering
\includegraphics[width=.99\linewidth]{Figures/MisMatchFinder/mismatchrateCleanSequencing.pdf}
\caption[Mismatchrate of different filtering methods]{Mismatchrate of different filtering methods on sequencing data simulated with ART\cite{Huang2011} for both 10x and 3x coverage; Mismatches correspond to simulated sequencing errors; all: no filters, overlap: only use the overlapping parts of paired end reads with consensus building (\protect\autoref{mmf-sec:consensus}), strict OL: overlap but reads \emph{must} agree, high BQ strict OL: strict OL with high BQ in both variants; A) Absolute counts B) counts from A normalised by the number of analysed bases all: all aligned bases, other: number of bases in read overlap}\label{fig:mmf-mismatchrate}
\end{figure}

By only using high base quality mismatches, where both reads agree on the mismatch 99.98\% of all sequencing errors could be eliminated and only 1 mismatch in 10M bases will be wrongly counted as a variant (\autoref{fig:mmf-mismatchrate}). This false discovery rate was multiple orders of magnitude lower than without consensus computation. The remaining error rate was lower than most tumour mutational burden estimates \cite{Alexandrov2020,Lawrence2013a}.


\subsubsection{Spike-in signature detection}
\label{mmf-sec:simSignatures}
With the technical errors eliminated in simulated data, used the same method in real world data. However, to also establish a baseline for detection limit and sensitivity of the method, we decided to first use a hybrid approach. We spiked somatic variants into a genuine low coverage WGS sequencing of a healthy control, reducing the amount of unknown variability from other published datasets.

While it would have been possible simulate the variants completely de novo, without any prior knowledge, we know that somatic mutations follow a certain pattern and there a mutational hotspots \cite{Chen2016,Moore2021}, so we decided to instead use the COSMIC database \cite{Tate2018,WSI2021} as the catalogue to select mutations from. This allowed us to randomly draw mutations, which occurred in a specific cancer subtype. By using COSMIC variants our simulation were less synthetic. The in-depth protocol is shown in \autoref{ch-mmfAppendix:spikein}. The downside of this method is that the spike-in were not predominantly introduced on shorter fragments, as it would be the case with real ctDNA. 

The follwing section discuss the results for the simulation of the very distinct SBS7a signature (see \autoref{fig:sig7a}) which is predominantly present in Melanoma (see \autoref{mmf-sec:melaSim}) and secondly the much flatter and more uniform SBS3 (see \autoref{A:fig:sig3}), which is a sign of defective homologous recombination in breast cancers (\autoref{mmf-sec:mbcSim}). 


\begin{figure}[ht]
\centering
\includegraphics[width=.9\linewidth]{Figures/MisMatchFinder/spikeInSanityCheck.pdf}
\caption[Signature analysis of spike-in somatic variants]{Signature analysis results of spiked-in somatic variants; signatures with a weight less than 1\% were collated into ``unknown``; The original spike-in signature was coloured in green (SBS3) and purple (SBS7a), unrelated signatures are coloured white and signatures corresponding to sequencing artefacts are coloured in lightgrey; r0.1 corresponds to approximately 0.1 variants per mega base; Weights were generated with deconstructSigs \cite{Rosenthal2016} }\label{fig:mmf-spikeinsanity}
\end{figure}

The spike-in was done at multiple different ratios, to simulate varying tumour purity and tumour mutational burden (TMB). \autoref{fig:mmf-spikeinsanity} shows the signature analysis result of the lowest spike-in ratio ``r0.1`` which corresponded to 0.1 somatic variants per mega base and resulted in approximately 300 variants for the whole genome. As the spike-in process had to satisfy certain quality measures, not all candidate variants coul be used. As such, the final simulated BAM contained 264 additional variants for the SBS3 simulation and 287 for the SBS7a equivalent. That corresponds to 304 and 364 ``tumour`` reads respectively within the $\approx$ 261 million reads of the simulated BAM. With increasing ratio, the spike-in signatures showed decreasing weights for other signatures, which likely got introduced due to the incomplete spike-in process(\autoref{ch-mmfAppendix:spikein}).


\begin{figure}[ht]
\centering
\includegraphics[width=.99\linewidth]{Figures/MisMatchFinder/deconstructionMethodsDifferences.pdf}
\caption[Signature weight differences for different deconvolution methods]{Signature weight differences for different deconvolution methods; Methods are the quadratic programming (QP) and iterative linea model (ILM); deconvolution was performed on the same counts generated with MisMatchFinder on 7 simulated dataset with increasing mutational burden from 5 to 100 mutations per mega base spike-in; for 0 mutations per mega base, the normal sample used for the spike-in was used}\label{fig:mmf-methodDifferences}
\end{figure}


\paragraph{Melanoma - UV exposure (SBS7a)}
\label{mmf-sec:melaSim}

With melanoma, normal TMB ranges from 0.1 to 100 mutations per mega base \cite{Alexandrov2020}, however Melanoma is usually seen as a very cancer with very high mutational load, which made it the ideal target for this new mutational based tool. With only the strict overlap (\autoref{mmf-sec:consensus}) and the germline (\autoref{mmf-sec:germlinefiltering}) filtering enabled, we could see that already from r5, which represented 16899 mutated reads (of 260 Mio.), we sqw an increase in signature SBS7a. While this signal is likely too low to trust in a real world setting, with r10, the signature weight is already 2\% and well established. Secondly, the method was very specific on this dataset, only SBS7a showed an increase with higher spike-in, which minor leaks to other $C>T$ heavy signatures like SBS2 and SBS30 (\Autoref{fig:mmf-methodDifferences,fig:mmf-spikeSBS7asignatures}), which partly already stemmed from the spike-in process, which was slightly enriched for SBS2 (\autoref{fig:mmf-spikeinsanity}B ``unknown``). All other signatures, which were present in the normal sample showed a decrease. This decrease was to accommodate an additional signature, as all signature weights need to sum up to one.


\begin{figure}[ht]
\centering
\includegraphics[width=.99\linewidth]{Figures/MisMatchFinder/SBS7SpikeInSignatureDifferencesFocussed.pdf}
\caption[Signature weights differences from normal for SBS7a spike-in]{Signature weights differences from normal for SBS7a spike-in; Weights were de-constructed with QP method in MisMatchFinder and the weights assigned to the normal sample used for the spike-in were subtracted; Only Signatures with $\text{original weight}\geq 1\%$ or a minimum difference of 0.5\% are shown. The full weights can be seen in \protect\autoref{A:fig:sbs7aspikeindifferences}; r0.1 corresponded to 0.1 mutations per mega base (287 variants) and r100 was the equivalent of 100 mutations per mega base (286974 variants)}\label{fig:mmf-spikeSBS7asignatures}
\end{figure}

\paragraph{Defective homologous recombination-based DNA damage repair (SBS3)}
\label{mmf-sec:mbcSim}

Just as with the SBS7a signatures, even for the much more diffuse signature SBS3, MisMatchFinder specifically picked out the spike-in signature and did not assign the additional mismatches to any other signature. There was a small increase in SBS4 for the very low mutation rate simulations, where no SBS3 was detected. Unsurprisingly, the detection limit for SBS3 was slightly higher than for SBS7a (5 vs. 15 mutations per mega base), because of its uniform profile. Exactly as with SBS7a, all other signatures showed a slight decrease, to accommodate the additional signature weight (\Autoref{fig:mmf-methodDifferences,fig:mmf-spikeSBS3signatures}). While the detection threshold was slightly higher than the currently assumed median TMB in breast cancer, especially triple negative breast cancer (TNBC) has shown a higher TMB, which was at comparable levels to the limit of detection we saw in this simulated dataset \cite{BarrosoSousa2020}.

\begin{figure}[ht]
\centering
\includegraphics[width=.99\linewidth]{Figures/MisMatchFinder/SBS3SpikeInSignatureDifferencesFocussed.pdf}
\caption[Signature weights differences from normal for SBS3 spike-in]{Signature weights differences from normal for SBS3 spike-in; Weights were deconstructed with QP method in MisMatchFinder and the weights assigned to the normal sample used for the spike-in were substracted; Only Signatures with $\text{original weight}\geq 1\%$ or a minimum difference of 0.5\% are shown. The full weights can be seen in \protect\autoref{A:fig:sbs3spikeindifferences}; r0.1 corresponds to 0.1 mutations per megabase (264 variants) and r100 is the equivalent of 100 mutations per megabase (285367 variants)}\label{fig:mmf-spikeSBS3signatures}
\end{figure}

\subsubsection{Germline filtering}
\label{mmf-sec:germlinefiltering}
With real patient data, we evaluated the effect of removing germline variants from the analysis. To this end, we used the same simulated samples from \autoref{mmf-sec:simSignatures}, where the reads were original ctDNA sequencing reads from a healthy person. These reads had a known natural background germline variant profile as any arbitrary sample would have.

\begin{figure}[ht]
\centering
\includegraphics[width=.99\linewidth]{Figures/MisMatchFinder/noGermlineFilterAnalysis.pdf}
\caption[Signature analysis without germline variant filtering]{Signature analysis without germline variant filtering; Weights were deconstructed with QP method in MisMatchFinder, but in contrast to \protect\autoref{fig:mmf-methodDifferences}, the filter removing all known germline variants was disabled}\label{fig:mmf-noGermlineFilterAnalysis}
\end{figure}

In stark contrast to the previous analysis (\autoref{fig:mmf-methodDifferences}), when retaining mismatches in known germline variant sites, the sensitivity of the method reduced significantly. Only for the SBS7a spike-in at the very highest mutation frequency (100 mutations per mega base) a signal was detected. This signal was still weaker than what was previously found with just 10 mutations per mega base. Unsurprisingly SBS3 performed worse, just as before, and no signal was detected at any frequency (\autoref{fig:mmf-noGermlineFilterAnalysis}).

This extreme change was caused by the much higher number of mismatches which were used in the analysis ($\approx 1.8$ Mio without germline filter and $\approx 130$K with germline filter).
This increase in mismatches in the analysis diluteed the spike-in variants. \autoref{fig:mmf-percentIncrease} showed that without the germline filter the additional found mismatches never exceeded 5\% which seemed to be the detection threshold for SBS7a. With germline filtering this threshold corresponded perfectly with the increase of SBS7a weight in those samples (\autoref{fig:mmf-methodDifferences}).

\begin{figure}[ht]
\centering
\includegraphics[width=.99\linewidth]{Figures/MisMatchFinder/spikeInPercentage.pdf}
\caption[Percent increase of mismatches in analysis with and without germline filter]{Percent increase of mismatches in analysis with and without germline filter; Values are normalised to the number of mismatches found in the normal sample (depicted as \num{0} mutations per mega base); dotted grey line shows the maximum increase in the left panel (without germline filter)}\label{fig:mmf-percentIncrease}
\end{figure}

While we had already established that the spike-in variants could not  be detected when retaining germline variant sites, the computed signature weights in the normal sample were vastly different as well. Without the germline filter, the most prevalent signatures were SBS1 and SBS5 which are thought to be molecular clock like signatures, related to the age of the individual \cite{Alexandrov2020}. In the germline filtered analysis the most prevalent signatures were SBS4 (tabacco smoking), SBS12 (unkown) and SBS46 (sequencing artefact). In general it seemed like the germline filter removes predominantly SBS1 and SBS5, while most other signatures remain the same (\autoref{fig:mmf-noGermlinePie}).

As the sample was acquired through a healthy donor blood bank, we had no way to verify if the individual was a smoker.

\begin{figure}[ht]
\centering
\includegraphics[width=.99\linewidth]{Figures/MisMatchFinder/noGermlineFilterSignaturesPieChart.pdf}
\caption[Signature weights of the normal sample with and without germline filter]{Signature weights of the normal sample with and without germline filter; MisMatchFinder derived signature weights with and without germline filter; weights below 1\% contribution are accumulated in ``unknown`` (darkgrey), lightgrey signatures show sequencing artefact signatures, yellow shows smoking related signatures and blue depicts APOBEC signatures}\label{fig:mmf-noGermlinePie}
\end{figure}
 
This convinced us that germline filtering, additionally to the consensus overlap analysis, was fundamentally important for the method to recover signal. In the following sections, unless further specified, the germline filter was enabled for all analysis.


\subsection{Real world data - the only things that matters}
\label{mmf-sec:realworld}

While simulated data is perfect to ensure the method performs as expected in edge cases and to estimate detection limits, only real world data allows the final examination if the model used for analysis can mirror biological concepts. To show our new method is usable for a variety of datasets, we used a mixture of different cancer types with different library preparation. In \autoref{mmf-sec:healthy} we focused on the analysis of healthy individuals. We generated a background noise model and excluded aging as one of the sources of variation from our data. Then we analysed two metastatic breast cancer patients with BRCA1 postive disease, comparing matched tumour-normal sequencing with MisMatchFinder. This dataset allowed us to evaluate how efficient germline filtering was (\autoref{mmf-sec:germlineArtifacts}) and how accurate and sensitive our method is when compared to the current gold standard of tumour-normal tissue analysis (\autoref{mmf-sec:matchedMBCB}).
A second dataset containing  multiple samples of two cell free DNA time points and corresponding tissue allowed us to validate performance of MisMatchFinder in a different cancer context (\autoref{mmf-sec:melpatients}). Lastly we analysed a dataset of 180 \todo{get exact number} tumour only cfDNA samples to show the clinical application of MisMatchFinder (\autoref{mmf-sec:tumourDetection}).

In the following section, we showed that MisMatchFinder exhibits barely any technical bias.

\subsubsection{Bias detection}
\label{mmf-sec:healthyBias}
This dataset with healthy samples is key to detect biases, because any variability that cannot be accounted to either age or gender is unwanted and will affect the cancer samples in the same way. We expected an increased mismatch rate in the older individuals do to the accumulation of somatic mutations due to ``clock like signatures`` \cite{Abascal2021}. In contrast, tumour samples should be biased based on tumour purity, as higher amount of tumour reads would result in a higher amount of mismatches from somatic mutations.
To verify that our assumptions were correct, we performed a principle component analysis (PCA) of the raw tri-nucleotide mismatch count numbers of each sample which MisMatchFinder can report alongside the weights of signatures.

% latex is dumb with this figure, i want it right HERE
\begin{figure}[!ht]
\centering
\includegraphics[width=.99\linewidth]{Figures/MisMatchFinder/countPCAsPC1vsPC2.pdf}
\caption[PCA of tri-nucleotide mismatch counts of real world data (PC1 and PC2)]{PCA (PC1 and PC2) of tri-nucleotide mismatch counts of healthy donor and tumour samples (melanoma and metastatic breast cancer) of varying purity; PCA was conducted on scaled and centered data}\label{fig:mmf-pca1v2}
\end{figure}


Neither age, not sex of the sample seemed to have any influence on the mismatches of the sample \autoref{fig:mmf-pca1v2}A,~B. In contrast, there seems to be a batch effect like structure with regards to the used flowcell on the sequencer and library preparation (\autoref{fig:mmf-pca1v2}C,~D). As these two are fairly intertwined, it is almost impossible to tease the two apart, however it seems like the flowcell bias is overarching multiple library preparations. Flowcell 1 contains samples from both \lq g\rq\ and \lq h\rq\ and  flowcell 3 both \lq a\rq\ and \lq d\rq, suggesting that the flowcell has more influence than the preparation. This is consistent with recent literature, which suggests, that there are more and less error prone flow cells \cite{Stoler2021}.

While there is a slight bias towards higher PC1 values for higher DNA input samples, which might be due to a higher library complexity when sequencing, it is fairly minor and this bias exists for every other method using de-duplicated sequencing data as it might have an effect on the non-redundant data available (\autoref{fig:mmf-pca1v2}E). Similarly, the very low coverage samples are at the very left of PC1, there is a substantial spread along the axis for the higher coverage samples as well (\autoref{fig:mmf-pca1v2}F). 

And just as we expected from the model and the biology, there is a hint of a separation for both tumour type and tumour purity, with the higher purity samples oriented toward the top right and the healthy and lower purity samples at the left (\autoref{fig:mmf-pca1v2}G,~H).

These tendencies can also be observed when looking at PC2 and PC3 (\autoref{A:fig:mmf-pca2v3}). PC3 still accounts for $\approx \text{9\%}$ of the observed variability and PC6 is the first component with an eigenvalue smaller than 1 suggesting that only the first five components should be retained for further analysis (explaining a cumulative 97.3\% of the variance). However, as we use the counts for signature deconstruction the PCA analysis only served as a quality control.


\subsubsection{Healthy cohort}
\label{mmf-sec:healthy}

We sequenced the 60 healthy samples, from varying age groups (\num{24}~yrs.-\num{70}~yrs. median: \num{48.5}~yrs.) with 24 males and 36 females, in the exact same way as the tumour only samples for MBCB and melanoma to an effective average coverage of 8x WGS, with mixed healthy samples and cancer samples on sequencing flow cells to account for and minimise batch effects.

With recent literature indicating a clear linear relationship of aging and somatic mutations \cite{Martincorena2018,Abascal2021,Cagan2022}, we were interested if the MisMatchFinder method can identify the accumulation of  somatic mutations with age. While the samples between 30 and 59 show the expected linear increase in mean mismatch rate, both the 20-29 and 60-69 year old samples did show the inverse, where young individuals exhibited a higher mismatch rate than older. This discrepancy could have been rooted in the germline filtering step as shown in \autoref{mmf-sec:germlineArtifacts}, or its a sign of loss of heterogeneity in the hematopoiesis shown in aging mice \cite{Ganuza2019}. Lastly, with only 40 healthy samples, we might not have had enough representation in each age group to detect subtle changes.Whatever the source, MisMatchFinder was not able to infer the age of a sample with the default settings in this dataset.

\begin{figure}[ht]
\centering
\includegraphics[width=.99\linewidth]{Figures/MisMatchFinder/MisMatchRateByAge.pdf}
\caption[Mismatchrates of healthy samples by age]{Mismatchrates of healthy samples by age: distribution of sample is shown as violin plots on the left hand of each group, with a boxplot and the mean indicated as a black box and a white dot respectively; Observed values were displayed as black dots on the right hand of each group}\label{fig:mmf-mmrByAge}
\end{figure}


\paragraph{Black list generation}
\label{mmf-sec:healthyBlacklist}
With the strong influence filtering of both technical errors (\autoref{mmf-sec:cleanSim}) and germline variants (\autoref{mmf-sec:germlinefiltering})  as background noise had on our method, we hypothesised that a blacklist of mismatches found in our healthy individuals would help us further cut down on unwanted background signal and refine the somatic mismatch calls. We therefore ran MisMatchFinder with significantly relaxed quality cut-offs to capture as much variation as possible. This included a reduction in mapping quality and base quality as well as not restricting the analysis to the highly accurate overlap part of the paired end reads. However we still restricted the analysis to the same highly mappable areas of the genome the same as for the tumour analysis as well as filtering already known germline variants for a better estimation of the impact of this filter step.

The site files generated through MisMatchFinder were then concatenated and aggregated to multiple blacklists with cut-offs of a variant present in at least 3, 5 or 10 times. The bash code used for the post processing of MisMatchFinder site files can be found in \autoref{lst-mmf:blacklist}.


\begin{figure}[ht]
\centering
\includegraphics[width=.99\linewidth]{Figures/MisMatchFinder/mmfBlackListStats.pdf}
\caption[Blacklisted mismatches from healthy individuals]{Blacklisted mismatches from healthy individuals: A) Histogram of frequency of mismatches found by at least n samples (multiplicity) B) Percentage of mismatches in healthy samples found in blacklist of at mismatches found in at least three healthy samples; violin plot with median as white dot (left) and real values (right)}\label{fig:mmf-BlackListStats}
\end{figure}

While there are a substantial amount of shared variants in the reduced parameter analysis out of the $\approx 15$ million mismatches, only 3413 are in more than 50\% of all samples (\autoref{fig:mmf-BlackListStats}A). However, when we used the default settings for the healthy samples and used the generated blacklist as a filter on average only 2\% of mismatches were removed by the blacklist assignment (min: 1\%, max: 3\%) when using the blacklist with at least three samples showing the mismatch (\autoref{fig:mmf-BlackListStats}B). When we used the ten sample blacklist, the mean filtering amount dropped to 0.1\% of mismatches of the sample (min: 0.04\% max: 0.3\%). We therefore concluded that the blacklist filtering step has no additional benefit and it was not included in MisMatchFinder . 

\subsubsection{MBCB patient samples}
\label{mmf-sec:brcapatients}
The first dataset of patients was two BRCA1/2 positive breast cancers. The data contained matched tumour, germline and ctDNA sequencing as high depth WGS for both patients. With the matched normal, we used the current standard protocol of somatic mutational pattern analysis (\autoref{mmf-sec:signatureanalysis}) and compared it with our new method (\autoref{mmf-sec:matchedMBCB}). 

As the sequencing data of the ctDNA is much higher depth than what is used in standard clinical practice for plasma sequencing, we down-sampled the data to 8x coverage, bringing it in line with the simulated data. By using several different seeds for the sampling, we generated pseudo technical replicates of the sequencing (\autoref{ch-mmfAppendix:subsampling}), which then in term gave an approximation of the stability of the results of MisMatchFinder.

The following section discuss how the germline filtering step had on real patient data. 

\paragraph{Germline artifacts}
\label{mmf-sec:germlineArtifacts}
As discussed above, the germline filter step is vital to boost the signal of somatic variants (\autoref{mmf-sec:germline}),.We were interested how many germline variants were not filtered out with our filtering step. The high depth matched healthy WGS samples of the breast cancer dataset was used for this analysis. We called germline variants on the matched normal using Strelka2 and compared the called variants with the sites reported by MisMatchFinder as somatic (retained after germline filtering) on the sub-sampled data. All variants with any quality filter assigned by Strelka2 were considered for this analysis, such that possible clonal hematopoiesis (CH) variants are still considered. \autoref{tab:mmf-germlineArtifacts} showed that on average 2100 germline variants were not filtered out per run. However, this only equated to 0.9\% for MBCB196 and 1.5\% for MBCB298 of all sites found to be mutated. While the exact numbers of any arbitrary sample will depend on the strictness of the parameters of the analysis as well as the mutation rate of the sample, with default parameters a similar result should be expected with other samples.

The germline variant removal was therefore very effective filtering the 3.75 (MBCB196) and 3.76 (MBCB298) million germline SNPs called by Strelka2 to less than 0.05\% of the original. As the genetic background in gnomAD is not balanced and shows a lack of non-european ancestry data \cite{Tiao2020}, this filtering could become less effective when analysing samples from indigenous or otherwise genetically less characterised patients, as their germline variants might not be recorded yet.

Nevertheless, this result combined with the effective filtering of technical errors (\autoref{mmf-sec:cleanSim}) suggested, that all the remaining sites are somatic mutations of either the healthy tissue or the cancer cells.

\begin{table}
\caption[Germline variants retained after germline filtering]{Germline variants retained after germline filtering with in MisMatchFinder analysis; Default parameters were used when running MisMatchFinder with gnomAD zarr for filtering. seed column showed the seed used to subsample the high depth sequencing BAM, ``mismatch sites`` column contains number of sites found to be changed, ``germline sites`` contains the number of sites also found with germline variant calling, fraction shows fraction of column 4 and 3}\label{tab:mmf-germlineArtifacts}
\centering
\begin{tabular}{|c|c|c|c|c|}
\toprule
\hline
\textbf{Patient ID} & \textbf{seed} & \textbf{mismatch sites} & \textbf{germline sites} & \textbf{fraction} \\
\hline
 & \num{1007} & \num{216950} &  \num{2107} & \num{0.0097}\\ 
 & \num{1234} & \num{217145} &  \num{2073} & \num{0.0095}\\ 
 & \num{1337} & \num{216823} &  \num{2080} & \num{0.0096}\\ 
 & \num{1717} & \num{217593} &  \num{2089} & \num{0.0096}\\ 
 & \num{2358} & \num{217317} &  \num{2097} & \num{0.0096}\\ 
 & \num{3311} & \num{217219} &  \num{2046} & \num{0.0094}\\ 
 & \num{5229} & \num{216876} &  \num{2062} & \num{0.0095}\\ 
 & \num{6060} & \num{217388} &  \num{2080} & \num{0.0096}\\ 
\multirow{-9}{*}{MBCB196} & \num{9876} & \num{217656} &  \num{2008} & \num{0.0092}\\ 
\hline
 & \num{1756} & \num{148495} &  \num{2168} & \num{0.0146}\\ 
 & \num{3599} & \num{149901} &  \num{2224} & \num{0.0148}\\ 
 & \num{4117} & \num{149382} &  \num{2277} & \num{0.0152}\\ 
 & \num{4306} & \num{149549} &  \num{2248} & \num{0.0150}\\ 
 & \num{4359} & \num{149805} &  \num{2205} & \num{0.0147}\\ 
 & \num{5788} & \num{150103} &  \num{2241} & \num{0.0149}\\ 
 & \num{5887} & \num{150099} &  \num{2287} & \num{0.0152}\\ 
 & \num{8387} & \num{149533} &  \num{2248} & \num{0.0150}\\ 
\multirow{-9}{*}{MBCB298} & \num{9754} & \num{149547} &  \num{2229} & \num{0.0149}\\
\hline
\bottomrule
\end{tabular}
\end{table}


Additionally, we were interested to see if there filtering did remove true somatic signal, by removing somatic variants which mirrored a known germline variant. We therefore annotated high confidence variants called with Strelka2 in both the MBCB tissue and cfDNA samples with a germline flag when that variant was previously found in gnomAD. Surprisingly we found that $\approx 50\%$ of somatic variants found in any sample were also found in gnomAD. To ensure these samples are no outliers, we also analysed the tissue samples from \autoref{ch:cascade} and saw that all samples had half of the somatic variants called already present in gnomAD (\autoref{fig:mmf-germlineStatus}A). While gnomAD is known to contain potential somatic contamination, these overlaps were most likely due to error prone sites in the genome and the higher rate of deaminations and transitions over transversions\cite{Meyerson2020}. To ensure our filtering did not skew the results we performed signature deconvolution on the somatic variants of a sample, which were not found in gnomAD and variants which were found in gnomAD. While there were minor signatures which were clinically relevant (SBS13 and SBS87) the majority were contains in the variants selection not contained in gnomAD. Especially SBS13's contribution was still bigger in the non-germline selection (\autoref{fig:mmf-germlineStatus}B vs C, \autoref{A:fig:signaturesGermlineSplit}).

\begin{figure}[ht]
\centering
\includegraphics[width=.99\linewidth]{Figures/MisMatchFinder/somaticVarsInGermlineSites.pdf}
\caption[Somatic variants found in germline sites]{Analysis of somatic variants with respect to germline database gnomAD: A) percentage of somatic variants called with Strelka2 found also in gnomAD; Violin plot with median as white dot (left) and values (right)  B) signature analysis of variants not found in gnomAD for sample MBCB196 cfDNA c) signature analysis of variants also found in gnomAD for sample MBCB196 cfDNA; Colours show cancer associated signatures: blue (APOBEC), red (UV exposure), orange (tobacco), purple (chemotherapy), light grey (sequencing artefacts), dark grey (everything below 1\% weight)}\label{fig:mmf-germlineStatus}
\end{figure}
  


In summary, the filtering is a very powerful step, which boosts the performance of our signature detection method significantly with minimal signal deterioration. The high overlap of germline database variants and somatic variants poses a challenge for perfect concordance between our method and the current gold standard and would be a good spot for further investigation especially when ageing signatures like SBS1 and SBS5, which are cause by deamination, are  of interest. These overlapping variants will be predominantly removed and were the most likely reason for the results seen on healthy individuals (\autoref{mmf-sec:healthyBias}). A potential solution would be a machine learning model to distinguish germline variants from somatic variants.

\paragraph{Matched tissue and cfDNA WGS samples}
\label{mmf-sec:matchedMBCB}

\begin{figure}[ht]
\centering
\includegraphics[width=.99\linewidth]{Figures/MisMatchFinder/mbcbWGSsignatures.pdf}
\caption[Signature weights for the WGS of two MBCB patients]{Signature weights for the WGS of two MBCB patients; Colours show cancer associated signatures: blue (APOBEC), red (UV exposure), orange (tobacco), purple (chemotherapy), light grey (sequencing artefacts), dark grey (everything below 1\% weight)}\label{fig:mmf-mbcbWGSsigPie}
\end{figure}
 
The matched tissue-normal WGS for the two metastatic breast cancer patients allowed a concordance analysis with a known truth signature. We called variants with Strelka2 and performed default signature deconvolution with sigminer to obtain weights. Due to their known germline BRCA1/2 mutations we expected a contribution of SBS3. Both the tissue and the cfDNA samples of patient MBCB196 show a greater than 3\% SBS3 as expected, however neither samples for MBCB298 showed SBS3 (\autoref{fig:mmf-mbcbWGSsigPie}).
 
\begin{figure}[ht]
\centering
\includegraphics[width=.99\linewidth]{Figures/MisMatchFinder/brca1BarPlots.pdf}
\caption[Signature weights for subsampled BRCA1 positive patients]{Signature weights for subsampled BRCA1 positive patients: each quadrant represents one high depth WGS sample downsampled to 8x with different seed (x-axis) signature weights per downsampling were shown in the columns in each quadrant. Colours represent clinically relevant signatures: blue (APOBEC), green (HRD), red (UV radiation); light grey and white show sequencing artefact and signatures of unknown significance respectively. Only signatures considered to be active (\autoref{mmf-sec:sigdetection}) were displayed}\label{fig:mmf-mbcbBarPlot}
\end{figure}

When applying the default parameter MisMatchFinder analysis to the downsampled WGS, we observed consistent results with any seed, suggesting that the signal is present in all reads and subsampling did not skew the results. Secondly, the expected SBS3 signature was found at $\approx 18\%$ (min: 14\% max: 21\%) in the tissue and $\approx 24\%$ (min: 20\% max: 26\%) in the cfDNA, recapitulating the results from the standard analysis, even slightly emphasising the clinical relevant results due to the signature activity filtering (\autoref{mmf-sec:sigdetection}). The chemotherapy related signatures 25, 31, and 87 were no reported anymore, which could have been caused by the germline filtering step, however these signatures are not clinically actionable and expected after chemotherapy treatment so their exclusion was not of any concern. Surprisingly, even though the APOBEC signatures SBS2 and SBS13 were observed in the normal signature deconvolution, MisMatchFinder did only find very low levels of SBS13 contribution in the cfDNA sample (mean: 0.4\% (min: 0.1\% max: 0.7\%) and no contribution in the tissue samples. 

However, MisMatchFinder was able to detect a high prevalence of SBS2 in both tissue (mean: 12\% min: 11\% max: 12\%) and cfDNA (mean: 69\% min: 65\% max 74\%) samples of MBCB298, indicating that MisMatchFinder was capable to detect APOBEC signatures. Surprisingly, even thought the WGS analysis with sigminer did not result in a SBS3 positive deconvolution, MisMatchFinder was able to recover the expected signature in the tissue samples (mean: 28\%, min:27\%, max: 29\%). As the tissue sample in this case was a FFPE sample, with a much higher number of somatic variants called and very low tumour purity ($\leq 13\%$) the standard analysis could have been overwhelmed with FFPE artefacts, which were successfully filtered out in MisMatchFinder. Interestingly, the cfDNA sample did not show any SBS3, but extensively high APOBEC activity. The absence of SBS3 could potentially be explained by reversion mutations in the cancer reenabling BRCA1/2 \cite{Lin2018a}, while the high APOBEC activity has been shown in some breast cancer types with Kataegis \cite{Alexandrov2020,Rebhandl2015}.

Both the tissue samples of MBCB196 and the cfDNA sample of MBCB298 showed activity of melanoma signatures SBS38 and SBS7b respectively. While it is unlikely that these were caused by UV exposure, the APOBEC deamination signature has similarities to UV exposure. We therefore thought the UV signatures are a leaky APOBEC signature rather than genuine UV exposure.

While MisMatchFinder did not detect the expected SBS3 signature in all samples, we could show a high concordance with the current gold standard analysis and MisMatchFinder revealed clinically relevant signatures SBS2 and SBS3. While the UV related signatures could be considered false positives, they only accompany a much larger clinically relevant signature and we therefore considered them to be at an acceptable level.

\subsubsection{Melanoma patients}
\label{mmf-sec:melpatients}

For melanoma real world data, we used a dataset, containing tumour-normal matched tissue WES with two additional longitudinal time points of cell free DNA sequenced both as WES and as lcWGS. This allowed us to compare the current standard signature analysis for both time points with the envisioned low coverage method MisMatchFinder was developed for.

With the help of the WES of both the tissue and the cfDNA samples, we established the gold standard to compare the MisMatchFinder result to.  Strelka2 was used to call somatic variants and the high confidence somatic SNPs were used to generate signature weights with sigminer \cite{Wang2021} using default parameters for the GRCh38 genome build and QP deconstruction method.

As expected from a skin melanoma, the tissue as well as both WES cfDNA samples revealed a high contribution of SBS7a and SBS7b, with approximately 50\%  of all somatic variants associated with these two signatures in the tissue and time point 1 and 27\% in time point 2. While several other signatures were called to be present in all samples, none of them had clinical relevance (\autoref{fig:mmf-melaWESsigPie}).

\begin{figure}[ht]
\centering
\includegraphics[width=.99\linewidth]{Figures/MisMatchFinder/melanomaWESsignatures.pdf}
\caption[Signature weights for the WES of two melanoma patients]{Signature weights for the WES of two melanoma patients; First column shows the results for the tissue baseline and middle and right column show the cfDNA; Colours show cancer associated signatures: blue (APOBEC), red (UV exposure), orange (tobacco), purple (chemotherapy), light grey (sequencing artefacts), dark grey (everything below 1\% weight)}\label{fig:mmf-melaWESsigPie}
\end{figure}
 
This high exposure of SBS7a and SBS7b was highly concordant with our analysis of the lcWGS sample of time point 1, where more than 50\% of all somatic mismatches signatures, which were called active (\autoref{mmf-sec:sigdetection}), were attributed to SBS7a and SBS7b. While the proportion of SBS7a to SBS7b is different between the WES result and the lcWGS, the weights for those signatures are very similar. Time point 2 on the other hand showed less agreement between WES (sigminer) and lcWGS (MisMatchFinder). While SBS7b was still detected at similar levels between both method, MisMatchFinder failed to detect SBS7a, which was the highest contributing signature at time point 2 using the somatic variants from WES. Additionally both lcWGS samples show a high prevalence of SBS3, which was not detected in the WES. While SBS3 is usually accredited to \textit{BRCA1/2} positive breast cancers, there have been reports of homology repair deficiency in melanomas. These mismatches might have been caused by subclonal variants, which are below detection threshold for conventional variant calling (\Autoref{fig:mmf-melaWESsigPie,fig:mmf-melaMMFsigPie}).

\begin{figure}[ht]
\centering
\includegraphics[width=.99\linewidth]{Figures/MisMatchFinder/melanomaMMFsignatures.pdf}
\caption[Signature weights of lcWGS of two melanoma samples]{Signature weights of lcWGS of two melanoma samples Colours show cancer associated signatures: blue (APOBEC), red (UV exposure), orange (tobacco), purple (chemotherapy), light grey (sequencing artefacts), dark grey (everything below 1\% weight)}\label{fig:mmf-melaMMFsigPie}
\end{figure}


\subsection{ Tumour detection analysis}
\label{mmf-sec:tumourDetection}

\todo[inline]{Add data about the glmnet and ichorCNA}
clinical testing, e.g. copy number analysis \cite{Homburger2019,Chen2021}


\begin{table}[ht]
\caption[Confusion matrix for MisMatchFinder leave one out validation on trainings set]{Confusion matrix for MisMatchFinder leave one out validation on trainings set}\label{tab:mmf-looMat}
\centering
\begin{tblr}{
	vlines,
	colspec=cccc,
	cell{3}{3} = {LimeGreen},
	cell{4}{4} = {LimeGreen},
	vline{1} = {1,2}{fg=white}
	}

\SetHline{1-4}{1pt}
\SetHline{3-4}{0.4pt}
\SetCell[r=2,c=2]{c}  & 1-2 & \SetCell[c=2]{c,bg=Goldenrod} True class & 1-4\\
\SetHline{3-4}{0.4pt}
 2-1 & 2-2 & positive & negative \\
 \SetHline{1-4}{0.4pt}
 \SetCell[r=2]{m,bg=Goldenrod} Prediction & positive & 21 & 5 \\
 \SetHline{2-4}{0.4pt}
 4-1 & negative & 19 & 55 \\
 \SetHline{1-4}{0.4pt} 
 \SetHline{1-4}{1pt} 

\end{tblr}
\end{table}

\section{Summary}
\todo[inline]{Write how awesome it is, but that it still needs improvemnet for clinical application}
